# 文档处理任务流程实现计划 - 服务层

## 服务层实现

### 1. 存储服务（后端）

**位置**: `notebook-backend/app/services/storage_service.py`

```python
import os
import tempfile
import logging
from typing import Optional
import minio
from minio.error import S3Error
from fastapi import UploadFile
from app.config import settings

logger = logging.getLogger(__name__)

class StorageService:
    """对象存储服务"""
    
    def __init__(self):
        """初始化Minio客户端"""
        self.minio_client = minio.Minio(
            endpoint=settings.MINIO_ENDPOINT,
            access_key=settings.MINIO_ACCESS_KEY,
            secret_key=settings.MINIO_SECRET_KEY,
            secure=settings.MINIO_USE_SSL
        )
    
    async def save_upload_file_temp(self, upload_file: UploadFile) -> str:
        """保存上传的文件到临时目录"""
        try:
            # 创建临时文件
            suffix = os.path.splitext(upload_file.filename)[1] if upload_file.filename else ""
            with tempfile.NamedTemporaryFile(delete=False, suffix=suffix) as temp_file:
                # 读取上传文件内容
                content = await upload_file.read()
                # 写入临时文件
                temp_file.write(content)
                return temp_file.name
        except Exception as e:
            logger.error(f"保存上传文件失败: {str(e)}")
            raise Exception(f"保存上传文件失败: {str(e)}")
    
    def upload_file_to_minio(self, file_path: str, bucket_name: str, object_key: str) -> bool:
        """上传文件到Minio存储"""
        try:
            # 确保存储桶存在
            if not self.minio_client.bucket_exists(bucket_name):
                self.minio_client.make_bucket(bucket_name)
                logger.info(f"创建存储桶: {bucket_name}")
            
            # 上传文件
            self.minio_client.fput_object(
                bucket_name=bucket_name,
                object_name=object_key,
                file_path=file_path
            )
            
            logger.info(f"文件已上传至 {bucket_name}/{object_key}")
            return True
        except S3Error as e:
            logger.error(f"Minio操作失败: {str(e)}")
            raise
        except Exception as e:
            logger.error(f"上传文件失败: {str(e)}")
            raise
    
    def download_file_from_minio(self, bucket_name: str, object_key: str, file_path: str) -> bool:
        """从Minio下载文件"""
        try:
            self.minio_client.fget_object(
                bucket_name=bucket_name,
                object_name=object_key,
                file_path=file_path
            )
            
            logger.info(f"文件已从 {bucket_name}/{object_key} 下载至 {file_path}")
            return True
        except S3Error as e:
            logger.error(f"Minio操作失败: {str(e)}")
            raise
        except Exception as e:
            logger.error(f"下载文件失败: {str(e)}")
            raise
    
    def get_presigned_url(self, bucket_name: str, object_key: str, expires: int = 3600) -> str:
        """获取预签名URL，用于直接访问文件"""
        try:
            url = self.minio_client.presigned_get_object(
                bucket_name=bucket_name,
                object_name=object_key,
                expires=expires
            )
            return url
        except S3Error as e:
            logger.error(f"获取预签名URL失败: {str(e)}")
            raise
        except Exception as e:
            logger.error(f"获取预签名URL失败: {str(e)}")
            raise
    
    def delete_file_from_minio(self, bucket_name: str, object_key: str) -> bool:
        """从Minio删除文件"""
        try:
            self.minio_client.remove_object(
                bucket_name=bucket_name,
                object_name=object_key
            )
            
            logger.info(f"文件已从 {bucket_name}/{object_key} 删除")
            return True
        except S3Error as e:
            logger.error(f"Minio操作失败: {str(e)}")
            raise
        except Exception as e:
            logger.error(f"删除文件失败: {str(e)}")
            raise
```

### 2. 向量存储服务（后端）

**位置**: `notebook-backend/app/services/vector_store_service.py`

```python
import logging
import uuid
import httpx
from typing import List, Dict, Any, Optional
from app.config import settings

logger = logging.getLogger(__name__)

class VectorStoreService:
    """向量存储服务"""
    
    def __init__(self):
        """初始化向量存储客户端"""
        self.qdrant_url = settings.QDRANT_URL
        self.qdrant_api_key = settings.QDRANT_API_KEY
        self.collection_name = settings.QDRANT_COLLECTION_NAME
        self.vector_size = settings.VECTOR_SIZE  # 向量维度
        
        # 确保集合存在
        self.ensure_collection_exists()
    
    def ensure_collection_exists(self):
        """确保向量集合存在，不存在则创建"""
        try:
            with httpx.Client(timeout=30.0) as client:
                # 检查集合是否存在
                url = f"{self.qdrant_url}/collections/{self.collection_name}"
                headers = {"Content-Type": "application/json"}
                
                if self.qdrant_api_key:
                    headers["api-key"] = self.qdrant_api_key
                
                response = client.get(url, headers=headers)
                
                # 如果集合不存在（状态码404），则创建集合
                if response.status_code == 404:
                    self.create_collection()
                elif response.status_code != 200:
                    logger.error(f"检查向量集合失败: {response.text}")
                    raise Exception(f"检查向量集合失败: {response.status_code}")
        except Exception as e:
            logger.error(f"确保向量集合存在失败: {str(e)}")
            raise
    
    def create_collection(self):
        """创建向量集合"""
        try:
            with httpx.Client(timeout=30.0) as client:
                url = f"{self.qdrant_url}/collections"
                headers = {"Content-Type": "application/json"}
                
                if self.qdrant_api_key:
                    headers["api-key"] = self.qdrant_api_key
                
                # 集合配置
                data = {
                    "name": self.collection_name,
                    "vectors": {
                        "size": self.vector_size,
                        "distance": "Cosine"  # 使用余弦相似度
                    }
                }
                
                response = client.put(url, headers=headers, json=data)
                response.raise_for_status()
                
                logger.info(f"成功创建向量集合: {self.collection_name}")
        except Exception as e:
            logger.error(f"创建向量集合失败: {str(e)}")
            raise
    
    async def store_vectors(self, vectors: List[List[float]], metadata: List[Dict[str, Any]]) -> bool:
        """存储向量到Qdrant"""
        try:
            # 准备批量点数据
            points = []
            for i, (vector, meta) in enumerate(zip(vectors, metadata)):
                point_id = meta.get("id") or f"{uuid.uuid4()}"
                points.append({
                    "id": point_id,
                    "vector": vector,
                    "payload": meta
                })
            
            # 批量上传向量
            async with httpx.AsyncClient(timeout=30.0) as client:
                url = f"{self.qdrant_url}/collections/{self.collection_name}/points"
                headers = {"Content-Type": "application/json"}
                
                if self.qdrant_api_key:
                    headers["api-key"] = self.qdrant_api_key
                    
                response = await client.put(url, headers=headers, json={"points": points})
                response.raise_for_status()
                
                logger.info(f"成功存储{len(points)}个向量到Qdrant")
                return True
        except Exception as e:
            logger.error(f"存储向量失败: {str(e)}")
            return False
    
    async def search_vectors(self, query_vector: List[float], limit: int = 5) -> List[Dict[str, Any]]:
        """搜索相似向量"""
        try:
            # 准备搜索请求
            search_params = {
                "vector": query_vector,
                "limit": limit
            }
            
            # 执行搜索
            async with httpx.AsyncClient(timeout=30.0) as client:
                url = f"{self.qdrant_url}/collections/{self.collection_name}/points/search"
                headers = {"Content-Type": "application/json"}
                
                if self.qdrant_api_key:
                    headers["api-key"] = self.qdrant_api_key
                
                response = await client.post(url, headers=headers, json=search_params)
                response.raise_for_status()
                
                result = response.json()
                return result.get("result", [])
        except Exception as e:
            logger.error(f"搜索向量失败: {str(e)}")
            return []
    
    async def delete_vectors(self, vector_ids: List[str]) -> bool:
        """删除向量"""
        try:
            # 准备删除请求
            delete_params = {
                "ids": vector_ids
            }
            
            # 执行删除
            async with httpx.AsyncClient(timeout=30.0) as client:
                url = f"{self.qdrant_url}/collections/{self.collection_name}/points/delete"
                headers = {"Content-Type": "application/json"}
                
                if self.qdrant_api_key:
                    headers["api-key"] = self.qdrant_api_key
                
                response = await client.post(url, headers=headers, json=delete_params)
                response.raise_for_status()
                
                logger.info(f"成功删除{len(vector_ids)}个向量")
                return True
        except Exception as e:
            logger.error(f"删除向量失败: {str(e)}")
            return False
```

### 3. 文本提取服务（后端）

**位置**: `notebook-backend/app/services/text_extraction_service.py`

```python
import os
import logging
from typing import Optional, Dict, Any
import PyPDF2
import docx
import pandas as pd
from bs4 import BeautifulSoup

logger = logging.getLogger(__name__)

class TextExtractionService:
    """文本提取服务"""
    
    def extract_text(self, file_path: str) -> Optional[str]:
        """从文件中提取文本"""
        logger.info(f"开始从文件提取文本: {file_path}")
        
        try:
            # 获取文件扩展名
            file_ext = os.path.splitext(file_path)[1].lower()
            
            # 根据文件类型调用不同的提取方法
            if file_ext in ['.txt', '.md', '.json', '.csv']:
                return self._extract_from_text_file(file_path)
            elif file_ext in ['.pdf']:
                return self._extract_from_pdf(file_path)
            elif file_ext in ['.doc', '.docx']:
                return self._extract_from_word(file_path)
            elif file_ext in ['.xls', '.xlsx']:
                return self._extract_from_excel(file_path)
            elif file_ext in ['.html', '.htm']:
                return self._extract_from_html(file_path)
            else:
                logger.warning(f"不支持的文件类型: {file_ext}")
                # 尝试以文本方式读取
                try:
                    with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                        return f.read()
                except Exception as e:
                    logger.error(f"以文本方式读取文件失败: {str(e)}")
                    return None
        except Exception as e:
            logger.exception(f"提取文本时出错: {str(e)}")
            return None
    
    def _extract_from_text_file(self, file_path: str) -> Optional[str]:
        """从文本文件中提取文本"""
        try:
            with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                return f.read()
        except Exception as e:
            logger.error(f"从文本文件提取文本失败: {str(e)}")
            return None
    
    def _extract_from_pdf(self, file_path: str) -> Optional[str]:
        """从PDF文件中提取文本"""
        try:
            text = ""
            with open(file_path, 'rb') as f:
                pdf_reader = PyPDF2.PdfReader(f)
                for page_num in range(len(pdf_reader.pages)):
                    text += pdf_reader.pages[page_num].extract_text() + "\n"
            return text
        except Exception as e:
            logger.error(f"从PDF提取文本失败: {str(e)}")
            return None
    
    def _extract_from_word(self, file_path: str) -> Optional[str]:
        """从Word文件中提取文本"""
        try:
            doc = docx.Document(file_path)
            text = "\n".join([paragraph.text for paragraph in doc.paragraphs])
            return text
        except Exception as e:
            logger.error(f"从Word文档提取文本失败: {str(e)}")
            return None
    
    def _extract_from_excel(self, file_path: str) -> Optional[str]:
        """从Excel文件中提取文本"""
        try:
            # 读取所有表格
            dfs = pd.read_excel(file_path, sheet_name=None)
            
            # 将所有表格转换为文本
            text = ""
            for sheet_name, df in dfs.items():
                text += f"=== Sheet: {sheet_name} ===\n"
                text += df.to_string(index=True, header=True) + "\n\n"
            
            return text
        except Exception as e:
            logger.error(f"从Excel提取文本失败: {str(e)}")
            return None
    
    def _extract_from_html(self, file_path: str) -> Optional[str]:
        """从HTML文件中提取文本"""
        try:
            with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                html_content = f.read()
            
            # 使用BeautifulSoup解析HTML
            soup = BeautifulSoup(html_content, 'html.parser')
            
            # 获取所有文本内容
            text = soup.get_text(separator="\n", strip=True)
            return text
        except Exception as e:
            logger.error(f"从HTML提取文本失败: {str(e)}")
            return None
```

### 4. 文本分块服务（后端）

**位置**: `notebook-backend/app/services/text_splitting_service.py`

```python
import logging
from typing import List, Dict, Any, Optional
import re

logger = logging.getLogger(__name__)

class TextSplittingService:
    """文本分块服务"""
    
    def split_text(self, text: str, chunk_size: int = 1000, chunk_overlap: int = 200) -> List[str]:
        """
        将文本分割成指定大小的块
        
        Args:
            text: 要分割的文本
            chunk_size: 每个块的最大字符数
            chunk_overlap: 相邻块之间的重叠字符数
            
        Returns:
            分割后的文本块列表
        """
        if not text:
            return []
        
        # 清理文本，删除多余空白字符
        cleaned_text = self._clean_text(text)
        
        # 使用段落分割文本
        paragraphs = self._split_into_paragraphs(cleaned_text)
        
        # 将段落合并成所需大小的块
        chunks = self._merge_paragraphs_into_chunks(paragraphs, chunk_size, chunk_overlap)
        
        return chunks
    
    def _clean_text(self, text: str) -> str:
        """清理文本，删除多余的空白字符"""
        # 将连续的空白字符替换为单个空格
        cleaned = re.sub(r'\s+', ' ', text)
        # 去除首尾空白
        cleaned = cleaned.strip()
        return cleaned
    
    def _split_into_paragraphs(self, text: str) -> List[str]:
        """将文本分割成段落"""
        # 使用多种分隔符匹配段落
        paragraphs = re.split(r'(\n\s*\n|\r\n\s*\r\n)', text)
        
        # 过滤空段落
        filtered_paragraphs = []
        for p in paragraphs:
            p = p.strip()
            if p:  # 只保留非空段落
                filtered_paragraphs.append(p)
        
        return filtered_paragraphs
    
    def _merge_paragraphs_into_chunks(self, paragraphs: List[str], chunk_size: int, chunk_overlap: int) -> List[str]:
        """将段落合并成所需大小的块"""
        chunks = []
        current_chunk = []
        current_size = 0
        
        for paragraph in paragraphs:
            paragraph_size = len(paragraph)
            
            # 如果段落太大，进行分割
            if paragraph_size > chunk_size:
                # 先处理当前块中已有的内容
                if current_chunk:
                    chunks.append(" ".join(current_chunk))
                    current_chunk = []
                    current_size = 0
                
                # 分割大段落
                for i in range(0, paragraph_size, chunk_size - chunk_overlap):
                    chunk = paragraph[i:i + chunk_size]
                    if chunk:
                        chunks.append(chunk)
            else:
                # 如果添加当前段落后超出块大小
                if current_size + paragraph_size > chunk_size:
                    # 保存当前块并开始新块
                    chunks.append(" ".join(current_chunk))
                    
                    # 新块开始时，保留一部分重叠内容
                    overlap_start = max(0, len(current_chunk) - chunk_overlap // 100)  # 简单起见，按段落数量计算重叠
                    current_chunk = current_chunk[overlap_start:] if overlap_start > 0 else []
                    current_size = sum(len(p) for p in current_chunk)
                
                # 添加当前段落到块
                current_chunk.append(paragraph)
                current_size += paragraph_size
        
        # 处理最后一个块
        if current_chunk:
            chunks.append(" ".join(current_chunk))
        
        return chunks
    
    def split_text_by_semantic(self, text: str, min_chunk_size: int = 500, max_chunk_size: int = 1500) -> List[str]:
        """
        根据语义边界分割文本
        
        Args:
            text: 要分割的文本
            min_chunk_size: 最小块大小
            max_chunk_size: 最大块大小
            
        Returns:
            分割后的文本块列表
        """
        # 此处实现更智能的基于语义的分割算法
        # TODO: 实现更复杂的语义分割算法
        return self.split_text(text, max_chunk_size, min_chunk_size // 5)
```

### 5. 嵌入向量服务（后端）

**位置**: `notebook-backend/app/services/embedding_service.py`

```python
import logging
import time
import os
import openai
import numpy as np
from typing import List, Dict, Any, Optional
from app.config import settings

logger = logging.getLogger(__name__)

class EmbeddingService:
    """嵌入向量服务"""
    
    def __init__(self):
        """初始化嵌入服务"""
        self.model_provider = settings.EMBEDDING_MODEL_PROVIDER
        self.model_name = settings.EMBEDDING_MODEL_NAME
        self.batch_size = settings.EMBEDDING_BATCH_SIZE
        self.max_retries = settings.EMBEDDING_MAX_RETRIES
        self.retry_delay = settings.EMBEDDING_RETRY_DELAY
        
        # 根据提供商配置API
        if self.model_provider == "openai":
            openai.api_key = settings.OPENAI_API_KEY
            openai.base_url = settings.OPENAI_API_BASE
        elif self.model_provider == "local":
            # 本地模型配置
            self.local_model_url = settings.LOCAL_EMBEDDING_MODEL_URL
    
    async def get_embeddings(self, texts: List[str]) -> List[List[float]]:
        """
        获取文本嵌入向量
        
        Args:
            texts: 文本列表
            
        Returns:
            向量列表
        """
        if not texts:
            return []
        
        # 批量处理，避免超出API限制
        all_embeddings = []
        for i in range(0, len(texts), self.batch_size):
            batch = texts[i:i + self.batch_size]
            batch_embeddings = await self._get_batch_embeddings(batch)
            all_embeddings.extend(batch_embeddings)
        
        return all_embeddings
    
    async def _get_batch_embeddings(self, batch_texts: List[str]) -> List[List[float]]:
        """获取一批文本的嵌入向量"""
        for attempt in range(self.max_retries):
            try:
                if self.model_provider == "openai":
                    return await self._get_openai_embeddings(batch_texts)
                elif self.model_provider == "local":
                    return await self._get_local_embeddings(batch_texts)
                else:
                    raise ValueError(f"不支持的模型提供商: {self.model_provider}")
            except Exception as e:
                logger.error(f"获取嵌入向量失败 (尝试 {attempt+1}/{self.max_retries}): {str(e)}")
                if attempt < self.max_retries - 1:
                    # 使用指数退避策略
                    delay = self.retry_delay * (2 ** attempt)
                    time.sleep(delay)
                else:
                    # 所有重试都失败了，抛出异常
                    raise
    
    async def _get_openai_embeddings(self, texts: List[str]) -> List[List[float]]:
        """使用OpenAI API获取嵌入向量"""
        try:
            response = await openai.Embedding.acreate(
                model=self.model_name,
                input=texts
            )
            
            # 提取嵌入向量
            embeddings = [item["embedding"] for item in response["data"]]
            return embeddings
        except Exception as e:
            logger.error(f"OpenAI嵌入向量API调用失败: {str(e)}")
            raise
    
    async def _get_local_embeddings(self, texts: List[str]) -> List[List[float]]:
        """使用本地模型获取嵌入向量"""
        try:
            import httpx
            
            async with httpx.AsyncClient(timeout=60.0) as client:
                response = await client.post(
                    self.local_model_url,
                    json={"texts": texts}
                )
                response.raise_for_status()
                result = response.json()
                
                return result["embeddings"]
        except Exception as e:
            logger.error(f"本地嵌入模型调用失败: {str(e)}")
            raise
```

### 6. 配置文件（后端）

**位置**: `notebook-backend/app/config.py`

```python
import os
from typing import Optional
from pydantic_settings import BaseSettings, SettingsConfigDict

class Settings(BaseSettings):
    """应用程序配置"""
    
    # 数据库配置
    POSTGRES_USER: str = "postgres"
    POSTGRES_PASSWORD: str = "postgres"
    POSTGRES_HOST: str = "localhost"
    POSTGRES_PORT: str = "5432"
    POSTGRES_DB: str = "notebook"
    DATABASE_URL: Optional[str] = None
    
    # JWT配置
    SECRET_KEY: str = "your-secret-key-here"
    ALGORITHM: str = "HS256"
    ACCESS_TOKEN_EXPIRE_MINUTES: int = 60 * 24  # 24小时
    
    # Minio配置
    MINIO_ENDPOINT: str = "localhost:9000"
    MINIO_ACCESS_KEY: str = "minioadmin"
    MINIO_SECRET_KEY: str = "minioadmin"
    MINIO_USE_SSL: bool = False
    MINIO_BUCKET_NAME: str = "documents"
    
    # Qdrant配置
    QDRANT_URL: str = "http://localhost:6333"
    QDRANT_API_KEY: Optional[str] = None
    QDRANT_COLLECTION_NAME: str = "documents"
    VECTOR_SIZE: int = 1536  # OpenAI嵌入维度
    
    # Celery配置
    CELERY_BROKER_URL: str = "redis://localhost:6379/0"
    CELERY_RESULT_BACKEND: str = "redis://localhost:6379/0"
    
    # 嵌入向量配置
    EMBEDDING_MODEL_PROVIDER: str = "openai"  # 'openai' 或 'local'
    EMBEDDING_MODEL_NAME: str = "text-embedding-ada-002"
    EMBEDDING_BATCH_SIZE: int = 10
    EMBEDDING_MAX_RETRIES: int = 3
    EMBEDDING_RETRY_DELAY: int = 1  # 秒
    
    # OpenAI配置
    OPENAI_API_KEY: Optional[str] = None
    OPENAI_API_BASE: Optional[str] = "https://api.openai.com/v1"
    
    # 本地模型配置
    LOCAL_EMBEDDING_MODEL_URL: Optional[str] = "http://localhost:8080/embed"
    
    # CORS配置
    CORS_ORIGINS: list = ["*"]
    
    # WebSocket配置
    WS_URL: str = "ws://localhost:8000"
    
    model_config = SettingsConfigDict(env_file=".env", env_file_encoding="utf-8", case_sensitive=True)
    
    def __init__(self, **data):
        super().__init__(**data)
        
        # 如果没有显式设置DATABASE_URL，则构建它
        if not self.DATABASE_URL:
            self.DATABASE_URL = f"postgresql://{self.POSTGRES_USER}:{self.POSTGRES_PASSWORD}@{self.POSTGRES_HOST}:{self.POSTGRES_PORT}/{self.POSTGRES_DB}"

# 创建配置实例
settings = Settings() 