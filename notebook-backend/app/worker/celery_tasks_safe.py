#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å®‰å…¨ç‰ˆæœ¬çš„Celeryä»»åŠ¡å¤„ç†å™¨
é¿å¼€SIGSEGVæ®µé”™è¯¯é—®é¢˜ï¼Œä½¿ç”¨ç®€åŒ–çš„ä¾èµ–é“¾
"""
import logging
import os
import time
from typing import Dict, Any, Optional

# è®¾ç½®ç¯å¢ƒæ ‡å¿—
os.environ['CELERY_WORKER'] = '1'

from app.core.config import settings
from app.celery_app import celery_app as app
from app.models.document import Document
from app.db.dependencies import get_db
from app.services.neo4j_service import Neo4jService
from app.services.task_service import TaskService

logger = logging.getLogger(__name__)

@app.task(bind=True, name="process_document_safe")
def process_document_safe(self, task_id: str, doc_id: int, processing_mode: str = "graph") -> Dict[str, Any]:
    """
    å®‰å…¨ç‰ˆæœ¬çš„æ–‡æ¡£å¤„ç†ä»»åŠ¡
    é¿å¼€å¤æ‚çš„æ™ºèƒ½å®ä½“ç»Ÿä¸€ï¼Œä½¿ç”¨åŸºç¡€å¤„ç†æµç¨‹
    """
    logger.info(f"ğŸ›¡ï¸ å¼€å§‹å®‰å…¨æ–‡æ¡£å¤„ç†: doc_id={doc_id}, task_id={task_id}, å¤„ç†æ¨¡å¼={processing_mode}")
    
    task_service = None
    
    try:
        # åˆå§‹åŒ–ä»»åŠ¡æœåŠ¡
        task_service = TaskService()
        
        # æ›´æ–°ä»»åŠ¡çŠ¶æ€ä¸ºè¿è¡Œä¸­
        logger.info(f"æ›´æ–°ä»»åŠ¡çŠ¶æ€: {task_id}, çŠ¶æ€: RUNNING")
        task_service.update_task_status(task_id, "RUNNING", progress=10)
        
        # æ£€æŸ¥æ˜¯å¦ä½¿ç”¨å®‰å…¨æ¨¡å¼
        use_safe_mode = getattr(settings, 'FORCE_SAFE_MODE', True)
        
        if use_safe_mode:
            logger.info("ğŸ›¡ï¸ ä½¿ç”¨å®‰å…¨æ¨¡å¼å¤„ç†æ–‡æ¡£")
            result = _process_document_safe_mode(doc_id, task_id, processing_mode, task_service)
        else:
            logger.info("âš¡ ä½¿ç”¨å®Œæ•´æ¨¡å¼å¤„ç†æ–‡æ¡£")
            result = _process_document_full_mode(doc_id, task_id, processing_mode, task_service)
        
        # æ›´æ–°ä»»åŠ¡ä¸ºå®ŒæˆçŠ¶æ€
        task_service.update_task_status(task_id, "COMPLETED", progress=100, result=result)
        
        logger.info(f"âœ… æ–‡æ¡£å¤„ç†å®Œæˆ: doc_id={doc_id}, task_id={task_id}")
        return result
        
    except Exception as e:
        error_msg = f"æ–‡æ¡£å¤„ç†å¤±è´¥: {str(e)}"
        logger.error(f"âŒ {error_msg}")
        
        # æ›´æ–°ä»»åŠ¡ä¸ºå¤±è´¥çŠ¶æ€
        if task_service:
            try:
                task_service.update_task_status(task_id, "FAILED", error=error_msg)
            except Exception as update_error:
                logger.error(f"âŒ æ›´æ–°ä»»åŠ¡çŠ¶æ€å¤±è´¥: {update_error}")
        
        # é‡æ–°æŠ›å‡ºå¼‚å¸¸
        raise


def _process_document_safe_mode(doc_id: int, task_id: str, processing_mode: str, 
                              task_service: TaskService) -> Dict[str, Any]:
    """
    å®‰å…¨æ¨¡å¼æ–‡æ¡£å¤„ç†
    é¿å¼€æ™ºèƒ½å®ä½“ç»Ÿä¸€ï¼Œä½¿ç”¨åŸºç¡€æ–‡æ¡£è§£æå’Œå­˜å‚¨
    """
    logger.info(f"ğŸ›¡ï¸ å¼€å§‹å®‰å…¨æ¨¡å¼å¤„ç†: doc_id={doc_id}")
    
    start_time = time.time()
    
    try:
        # 1. è·å–æ–‡æ¡£ä¿¡æ¯
        task_service.update_task_status(task_id, "RUNNING", progress=20)
        
        db = next(get_db())
        document = db.query(Document).filter(Document.id == doc_id).first()
        
        if not document:
            raise ValueError(f"æ–‡æ¡£æœªæ‰¾åˆ°: doc_id={doc_id}")
        
        logger.info(f"è·å–æ–‡æ¡£: {document.title}, æ–‡ä»¶è·¯å¾„: {document.file_path}")
        
        # 2. åŸºç¡€æ–‡æ¡£è§£æ
        task_service.update_task_status(task_id, "RUNNING", progress=40)
        
        from app.services.document_parser import DocumentParser
        parser = DocumentParser()
        
        # è§£ææ–‡æ¡£å†…å®¹
        parsed_content = parser.parse_file(document.file_path)
        logger.info(f"æ–‡æ¡£è§£æå®Œæˆï¼Œå†…å®¹é•¿åº¦: {len(parsed_content)}")
        
        # 3. ç®€å•åˆ†å—
        task_service.update_task_status(task_id, "RUNNING", progress=60)
        
        chunks = _create_simple_chunks(parsed_content, doc_id)
        logger.info(f"æ–‡æ¡£åˆ†å—å®Œæˆï¼Œåˆ†å—æ•°é‡: {len(chunks)}")
        
        # 4. åŸºç¡€å­˜å‚¨ï¼ˆè·³è¿‡å‘é‡åŒ–å’Œæ™ºèƒ½å¤„ç†ï¼‰
        task_service.update_task_status(task_id, "RUNNING", progress=80)
        
        if processing_mode == "graph":
            storage_result = _store_chunks_to_neo4j(chunks, document)
        else:
            storage_result = {"status": "success", "chunks_stored": len(chunks)}
        
        # 5. æ›´æ–°æ–‡æ¡£çŠ¶æ€
        document.processing_status = "completed"
        document.chunk_count = len(chunks)
        db.commit()
        
        processing_time = time.time() - start_time
        
        result = {
            "status": "success",
            "processing_mode": "safe",
            "document_id": doc_id,
            "chunks_created": len(chunks),
            "processing_time": processing_time,
            "storage_result": storage_result,
            "message": "å®‰å…¨æ¨¡å¼å¤„ç†å®Œæˆ"
        }
        
        logger.info(f"ğŸ‰ å®‰å…¨æ¨¡å¼å¤„ç†å®Œæˆ: {processing_time:.2f}ç§’")
        return result
        
    except Exception as e:
        logger.error(f"âŒ å®‰å…¨æ¨¡å¼å¤„ç†å¤±è´¥: {str(e)}")
        raise


def _process_document_full_mode(doc_id: int, task_id: str, processing_mode: str,
                              task_service: TaskService) -> Dict[str, Any]:
    """
    å®Œæ•´æ¨¡å¼æ–‡æ¡£å¤„ç†
    ä½¿ç”¨æ™ºèƒ½å®ä½“ç»Ÿä¸€ç­‰é«˜çº§åŠŸèƒ½
    """
    logger.info(f"âš¡ å¼€å§‹å®Œæ•´æ¨¡å¼å¤„ç†: doc_id={doc_id}")
    
    # è¿™é‡Œå¯ä»¥è°ƒç”¨åŸå§‹çš„å¤æ‚å¤„ç†é€»è¾‘
    # ä½†åœ¨å½“å‰é˜¶æ®µï¼Œä¸ºäº†é¿å…SIGSEGVï¼Œæš‚æ—¶å›é€€åˆ°å®‰å…¨æ¨¡å¼
    logger.warning("å®Œæ•´æ¨¡å¼æš‚æ—¶ä¸å¯ç”¨ï¼Œå›é€€åˆ°å®‰å…¨æ¨¡å¼")
    return _process_document_safe_mode(doc_id, task_id, processing_mode, task_service)


def _create_simple_chunks(content: str, doc_id: int, chunk_size: int = 1000) -> list:
    """
    åˆ›å»ºç®€å•çš„æ–‡æœ¬åˆ†å—
    """
    chunks = []
    
    # æŒ‰æ®µè½åˆ†å‰²
    paragraphs = content.split('\n\n')
    
    current_chunk = ""
    chunk_index = 0
    
    for paragraph in paragraphs:
        paragraph = paragraph.strip()
        if not paragraph:
            continue
        
        # å¦‚æœå½“å‰å—åŠ ä¸Šæ–°æ®µè½è¶…è¿‡å¤§å°é™åˆ¶ï¼Œåˆ™åˆ›å»ºæ–°å—
        if len(current_chunk) + len(paragraph) > chunk_size and current_chunk:
            chunks.append({
                'id': f"doc_{doc_id}_chunk_{chunk_index}",
                'content': current_chunk,
                'chunk_index': chunk_index,
                'document_id': doc_id,
                'start_pos': 0,  # ç®€åŒ–ä½ç½®ä¿¡æ¯
                'end_pos': len(current_chunk)
            })
            current_chunk = paragraph
            chunk_index += 1
        else:
            current_chunk += "\n\n" + paragraph if current_chunk else paragraph
    
    # æ·»åŠ æœ€åä¸€ä¸ªå—
    if current_chunk:
        chunks.append({
            'id': f"doc_{doc_id}_chunk_{chunk_index}",
            'content': current_chunk,
            'chunk_index': chunk_index,
            'document_id': doc_id,
            'start_pos': 0,
            'end_pos': len(current_chunk)
        })
    
    return chunks


def _store_chunks_to_neo4j(chunks: list, document) -> Dict[str, Any]:
    """
    å°†åˆ†å—å­˜å‚¨åˆ°Neo4jï¼ˆåŸºç¡€ç‰ˆæœ¬ï¼Œæ— å‘é‡åŒ–ï¼‰
    """
    try:
        neo4j_service = Neo4jService()
        
        # åˆ›å»ºæ–‡æ¡£èŠ‚ç‚¹
        doc_query = """
        MERGE (d:Document {id: $doc_id})
        SET d.title = $title,
            d.file_path = $file_path,
            d.chunk_count = $chunk_count,
            d.created_at = datetime(),
            d.processing_mode = 'safe'
        RETURN d
        """
        
        neo4j_service.execute_query(doc_query, {
            'doc_id': document.id,
            'title': document.title,
            'file_path': document.file_path,
            'chunk_count': len(chunks)
        })
        
        # åˆ›å»ºåˆ†å—èŠ‚ç‚¹
        chunks_stored = 0
        for chunk in chunks:
            chunk_query = """
            CREATE (c:Chunk {
                id: $chunk_id,
                content: $content,
                chunk_index: $chunk_index,
                document_id: $document_id,
                start_pos: $start_pos,
                end_pos: $end_pos,
                created_at: datetime()
            })
            WITH c
            MATCH (d:Document {id: $document_id})
            CREATE (d)-[:HAS_CHUNK]->(c)
            RETURN c
            """
            
            neo4j_service.execute_query(chunk_query, {
                'chunk_id': chunk['id'],
                'content': chunk['content'],
                'chunk_index': chunk['chunk_index'],
                'document_id': chunk['document_id'],
                'start_pos': chunk['start_pos'],
                'end_pos': chunk['end_pos']
            })
            chunks_stored += 1
        
        logger.info(f"âœ… Neo4jå­˜å‚¨å®Œæˆ: {chunks_stored} ä¸ªåˆ†å—")
        
        return {
            "status": "success",
            "chunks_stored": chunks_stored,
            "storage_type": "neo4j_basic"
        }
        
    except Exception as e:
        logger.error(f"âŒ Neo4jå­˜å‚¨å¤±è´¥: {str(e)}")
        return {
            "status": "error",
            "error": str(e),
            "chunks_stored": 0
        }


@app.task(bind=True, name="test_safe_task")
def test_safe_task(self) -> Dict[str, Any]:
    """
    æµ‹è¯•å®‰å…¨ä»»åŠ¡å¤„ç†
    """
    logger.info("ğŸ§ª å¼€å§‹å®‰å…¨ä»»åŠ¡æµ‹è¯•")
    
    try:
        import time
        time.sleep(2)  # æ¨¡æ‹Ÿå¤„ç†
        
        result = {
            "status": "success",
            "message": "å®‰å…¨ä»»åŠ¡æµ‹è¯•å®Œæˆ",
            "timestamp": time.time(),
            "worker_pid": os.getpid()
        }
        
        logger.info("âœ… å®‰å…¨ä»»åŠ¡æµ‹è¯•æˆåŠŸ")
        return result
        
    except Exception as e:
        logger.error(f"âŒ å®‰å…¨ä»»åŠ¡æµ‹è¯•å¤±è´¥: {str(e)}")
        raise 