# -*- coding: utf-8 -*-
import os
import asyncio
import logging
import traceback
from app.core.celery_app import celery_app
from app.database import get_db, SessionLocal
from app.services.task_service import TaskService
from app.services.document_service import DocumentService
from app.services.storage_service import StorageService
from app.services.task_detail_service import TaskDetailService
from app.ws.connection_manager import ws_manager
from app.models.task import TaskStatus, TaskStepStatus
from datetime import datetime, timezone
from app.core.config import settings
import traceback
from app.models.document import DocumentStatus
from app.worker.websocket_manager import WebSocketManager


logger = logging.getLogger(__name__)
ws_manager = WebSocketManager()

@celery_app.task(bind=True, name="test_wikipedia_proxy")
def test_wikipedia_proxy_task(self, entity_name: str, entity_type: str = None):
    """æµ‹è¯•Wikipediaä»£ç†è¿æ¥çš„Celeryä»»åŠ¡"""
    logger.info(f"å¼€å§‹æµ‹è¯•Wikipediaä»£ç†è¿æ¥: entity_name={entity_name}, entity_type={entity_type}")
    
    try:
        from app.services.wikipedia_mcp_server import WikipediaMCPServer
        
        # åˆå§‹åŒ–WikipediaæœåŠ¡å™¨
        server = WikipediaMCPServer()
        logger.info("Wikipedia MCPæœåŠ¡å™¨åˆå§‹åŒ–æˆåŠŸ")
        
        # æ‰§è¡Œæœç´¢
        result = server.search_entity(entity_name, entity_type)
        logger.info(f"Wikipediaæœç´¢å®Œæˆ: found={result.get('found', False)}")
        
        return {
            "status": "success",
            "entity_name": entity_name,
            "entity_type": entity_type,
            "search_result": result,
            "proxy_working": True
        }
        
    except Exception as e:
        error_msg = f"Wikipediaä»£ç†æµ‹è¯•å¤±è´¥: {str(e)}"
        logger.error(error_msg)
        logger.error(f"é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
        
        return {
            "status": "error",
            "entity_name": entity_name,
            "entity_type": entity_type,
            "error": error_msg,
            "proxy_working": False
        }


@celery_app.task(bind=True, name="process_document")
def process_document(self, doc_id: int, task_id: str, file_path: str, processing_mode: str = "rag"):
    """å¤„ç†æ–‡æ¡£çš„ä»»åŠ¡ - è°ƒåº¦å™¨"""
    logger.info(f"å¼€å§‹å¤„ç†æ–‡æ¡£ä»»åŠ¡: doc_id={doc_id}, task_id={task_id}, å¤„ç†æ¨¡å¼={processing_mode}")
    
    # æ ¹æ®å¤„ç†æ¨¡å¼é€‰æ‹©å¯¹åº”çš„å¤„ç†å™¨
    if processing_mode == "rag":
        from app.worker.processing.rag_processor import run as rag_processor_run
        asyncio.run(rag_processor_run(doc_id, task_id, file_path))
    elif processing_mode == "graph":
        from app.worker.processing.graph_processor import run as graph_processor_run
        asyncio.run(graph_processor_run(doc_id, task_id, file_path))
    else:
        raise ValueError(f"ä¸æ”¯æŒçš„å¤„ç†æ¨¡å¼: {processing_mode}")
    
    return {"status": "completed", "doc_id": doc_id, "task_id": task_id, "processing_mode": processing_mode}



async def push_task_update(task_id: str, task_service, task_detail_service=None):
    """æ¨é€ä»»åŠ¡çŠ¶æ€æ›´æ–°"""
    try:
        # è·å–å®Œæ•´ä»»åŠ¡çŠ¶æ€
        task_data = await task_service.get_task_with_details(task_id)
        
        # å¦‚æœæä¾›äº†task_detail_serviceï¼Œè·å–ä»»åŠ¡è¯¦æƒ…
        if task_detail_service:
            task_details = task_detail_service.get_task_details_by_task_id(task_id)
            task_details_data = [
                {
                    "id": td.id,
                    "step_name": td.step_name,
                    "step_order": td.step_order,
                    "status": td.status,
                    "progress": td.progress,
                    "details": td.details,
                    "error_message": td.error_message,
                    "started_at": td.started_at.isoformat() if td.started_at else None,
                    "completed_at": td.completed_at.isoformat() if td.completed_at else None,
                    "created_at": td.created_at.isoformat()
                }
                for td in task_details
            ]
            
            # æ·»åŠ ä»»åŠ¡è¯¦æƒ…åˆ°æ¨é€æ•°æ®
            task_data["task_details"] = task_details_data
        
        # å¼‚æ­¥æ¨é€åˆ°WebSocket
        from app.worker.websocket_manager import WebSocketManager
        ws_manager = WebSocketManager()
        await ws_manager.send_update(task_id, {
            "event": "task_update",
            "data": task_data
        })
    except Exception as e:
        logger.error(f"æ¨é€ä»»åŠ¡æ›´æ–°å¤±è´¥: {str(e)}")

# å–æ¶ˆä»»åŠ¡çš„Celeryä»»åŠ¡
@celery_app.task(name="cancel_document_task")
def cancel_document_task(task_id: str):
    """å–æ¶ˆæ–‡æ¡£å¤„ç†ä»»åŠ¡"""
    # è¿™é‡Œå¯ä»¥æ·»åŠ å–æ¶ˆé€»è¾‘ï¼Œä¾‹å¦‚å‘å¤„ç†è¿›ç¨‹å‘é€ç»ˆæ­¢ä¿¡å·
    # ç”±äºCeleryä»»åŠ¡ä¸€æ—¦å¼€å§‹æ‰§è¡Œå°±ä¸å®¹æ˜“è¢«æ‰“æ–­ï¼Œè¿™é‡Œæˆ‘ä»¬ä¸»è¦æ˜¯æ ‡è®°ä»»åŠ¡çŠ¶æ€ä¸ºå–æ¶ˆ
    asyncio.run(cancel_document_task_async(task_id))
    return {"status": "cancelled", "task_id": task_id}

async def cancel_document_task_async(task_id: str):
    """å¼‚æ­¥å–æ¶ˆæ–‡æ¡£å¤„ç†ä»»åŠ¡"""
    session = SessionLocal()
    try:
        task_service = TaskService(session)
        task_detail_service = TaskDetailService(session)
        
        # æ›´æ–°ä»»åŠ¡çŠ¶æ€ä¸ºå·²å–æ¶ˆ
        await task_service.update_task_status(
            task_id=task_id,
            status=TaskStatus.CANCELLED
        )
        
        # æ¨é€çŠ¶æ€æ›´æ–°
        await push_task_update(task_id, task_service, task_detail_service)
    finally:
        session.close()


# ğŸ†• å¢é‡å®ä½“ç»Ÿä¸€ä»»åŠ¡
@celery_app.task(bind=True, name="incremental_entity_unification")
def incremental_entity_unification_task(self, document_id, task_id, entities_data, mode="incremental"):
    """å¢é‡å®ä½“ç»Ÿä¸€Celeryä»»åŠ¡"""
    logger.info("Starting entity unification task: doc_id=%s, task_id=%s, mode=%s", document_id, task_id, mode)
    
    return asyncio.run(_execute_entity_unification(
        document_id=document_id,
        task_id=task_id, 
        entities_data=entities_data,
        mode=mode
    ))


# ğŸ†• å…¨å±€è¯­ä¹‰å®ä½“ç»Ÿä¸€ä»»åŠ¡ (æ–°ç‰ˆæœ¬)
@celery_app.task(bind=True, name="global_semantic_entity_unification")
def global_semantic_entity_unification_task(self, document_id, task_id, entities_data):
    """å…¨å±€è¯­ä¹‰å®ä½“ç»Ÿä¸€Celeryä»»åŠ¡ - ä½¿ç”¨LLMå’ŒNeo4jé‡‡æ ·"""
    logger.info("Starting global semantic entity unification: doc_id=%s, task_id=%s, entities=%d", 
                document_id, task_id, len(entities_data))
    
    return asyncio.run(_execute_global_semantic_unification(
        document_id=document_id,
        task_id=task_id, 
        entities_data=entities_data
    ))


async def _execute_entity_unification(document_id, task_id, entities_data, mode):
    """æ‰§è¡Œå®ä½“ç»Ÿä¸€"""
    session = SessionLocal()
    
    try:
        # è·å–æœåŠ¡å®ä¾‹
        task_service = TaskService(session)
        task_detail_service = TaskDetailService(session)
        
        # æ›´æ–°ä»»åŠ¡çŠ¶æ€
        await task_service.update_task_status(
            task_id=task_id,
            status=TaskStatus.RUNNING
        )
        
        # æ¨é€çŠ¶æ€æ›´æ–°
        await push_task_update(task_id, task_service, task_detail_service)
        
        # æ‰§è¡Œç»Ÿä¸€é€»è¾‘
        if mode == "incremental":
            result = await _execute_incremental_unification(entities_data, task_id, task_detail_service)
        elif mode == "sampling":
            result = await _execute_sampling_unification(entities_data, task_id, task_detail_service)
        else:
            raise ValueError("Unknown unification mode: %s" % mode)
        
        # æ›´æ–°ä»»åŠ¡çŠ¶æ€ä¸ºå®Œæˆ
        await task_service.update_task_status(
            task_id=task_id,
            status=TaskStatus.COMPLETED
        )
        
        # æ¨é€æœ€ç»ˆçŠ¶æ€
        await push_task_update(task_id, task_service, task_detail_service)
        
        logger.info("Entity unification completed: %s", result.get('summary', 'No summary'))
        return result
        
    except Exception as e:
        logger.error("Entity unification failed: %s", str(e))
        logger.error(f"å¼‚å¸¸è°ƒç”¨æ ˆ:\n{traceback.format_exc()}")
        
        # æ›´æ–°ä»»åŠ¡çŠ¶æ€ä¸ºå¤±è´¥
        await task_service.update_task_status(
            task_id=task_id,
            status=TaskStatus.FAILED,
            error_message=str(e)
        )
        
        # æ¨é€é”™è¯¯çŠ¶æ€
        await push_task_update(task_id, task_service, task_detail_service)
        raise
        
    finally:
        session.close()


async def _execute_global_semantic_unification(document_id, task_id, entities_data):
    """æ‰§è¡Œå…¨å±€è¯­ä¹‰å®ä½“ç»Ÿä¸€ - ä½¿ç”¨æ–°çš„v2æœåŠ¡"""
    session = SessionLocal()
    
    try:
        # è·å–æœåŠ¡å®ä¾‹
        task_service = TaskService(session)
        task_detail_service = TaskDetailService(session)
        
        # æ›´æ–°ä»»åŠ¡çŠ¶æ€
        await task_service.update_task_status(
            task_id=task_id,
            status=TaskStatus.RUNNING
        )
        
        # æ¨é€çŠ¶æ€æ›´æ–°
        await push_task_update(task_id, task_service, task_detail_service)
        
        # åˆ›å»ºä»»åŠ¡è¯¦æƒ…è®°å½•
        detail = task_detail_service.create_task_detail(
            task_id=task_id,
            step_name="å…¨å±€è¯­ä¹‰å®ä½“ç»Ÿä¸€",
            step_order=0
        )
        
        # æ›´æ–°è¯¦æƒ…çŠ¶æ€ä¸ºè¿è¡Œä¸­
        task_detail_service.update_task_detail(
            task_detail_id=detail.id,
            status=TaskStatus.RUNNING,
            progress=10,
            details={"step": "åˆå§‹åŒ–å…¨å±€è¯­ä¹‰ç»Ÿä¸€æœåŠ¡", "entity_count": len(entities_data)}
        )
        
        # å¯¼å…¥æ–°çš„å…¨å±€å®ä½“ç»Ÿä¸€æœåŠ¡
        from app.services.global_entity_unification_service_v2 import (
            get_global_entity_unification_service, GlobalUnificationConfig
        )
        from app.models.entity import Entity
        
        # åˆ›å»ºé…ç½®
        config = GlobalUnificationConfig(
            max_sample_entities_per_type=50,
            min_entities_for_unification=2,
            enable_cross_document_sampling=True,
            llm_confidence_threshold=0.7,
            max_batch_size=20,
            enable_quality_boost=True
        )
        
        # è·å–å…¨å±€ç»Ÿä¸€æœåŠ¡å®ä¾‹
        global_service = get_global_entity_unification_service(config)
        
        # è½¬æ¢å®ä½“æ•°æ®ä¸ºå®ä½“å¯¹è±¡
        entities = []
        for data in entities_data:
            try:
                entity = Entity(
                    id=data.get('id'),
                    name=data.get('name'),
                    type=data.get('type', 'unknown'),
                    entity_type=data.get('entity_type', data.get('type', 'unknown')),
                    description=data.get('description', ''),
                    properties=data.get('properties', {}),
                    confidence=data.get('confidence', 0.8),
                    source_text=data.get('source_text', ''),
                    start_pos=data.get('start_pos', 0),
                    end_pos=data.get('end_pos', 0),
                    chunk_neo4j_id=data.get('chunk_neo4j_id'),
                    document_postgresql_id=data.get('document_postgresql_id'),
                    document_neo4j_id=data.get('document_neo4j_id'),
                    embedding=data.get('embedding'),
                    quality_score=data.get('quality_score', 0.8),
                    importance_score=data.get('importance_score', 0.5)
                )
                entities.append(entity)
            except Exception as e:
                logger.warning("è·³è¿‡æ— æ•ˆå®ä½“æ•°æ®: %s", str(e))
                continue
        
        logger.info("æˆåŠŸè½¬æ¢ %d ä¸ªå®ä½“å¯¹è±¡ç”¨äºå…¨å±€è¯­ä¹‰ç»Ÿä¸€", len(entities))
        
        # æ›´æ–°ä»»åŠ¡è¯¦æƒ…
        task_detail_service.update_task_detail(
            task_detail_id=detail.id,
            status=TaskStatus.RUNNING,
            progress=30,
            details={"step": "å¼€å§‹å…¨å±€è¯­ä¹‰ç»Ÿä¸€", "validated_entities": len(entities)}
        )
        
        # æ‰§è¡Œå…¨å±€è¯­ä¹‰ç»Ÿä¸€
        unification_result = await global_service.unify_entities_for_document(
            new_entities=entities,
            document_id=document_id
        )
        
        # æ›´æ–°ä»»åŠ¡è¯¦æƒ…
        task_detail_service.update_task_detail(
            task_detail_id=detail.id,
            status=TaskStatus.RUNNING,
            progress=80,
            details={
                "step": "å…¨å±€è¯­ä¹‰ç»Ÿä¸€å®Œæˆ",
                "total_processed": unification_result.total_entities_processed,
                "entities_merged": unification_result.entities_merged,
                "entities_deleted": unification_result.entities_deleted,
                "relationships_updated": unification_result.relationships_updated,
                "processing_time": unification_result.processing_time,
                "type_statistics": unification_result.type_statistics
            }
        )
        
        # æœ€ç»ˆå®Œæˆ
        task_detail_service.update_task_detail(
            task_detail_id=detail.id,
            status=TaskStatus.COMPLETED,
            progress=100,
            details={
                "input_entities": len(entities_data),
                "total_processed": unification_result.total_entities_processed,
                "entities_merged": unification_result.entities_merged,
                "entities_deleted": unification_result.entities_deleted,
                "relationships_updated": unification_result.relationships_updated,
                "processing_time": unification_result.processing_time,
                "type_statistics": unification_result.type_statistics,
                "errors": unification_result.errors,
                "mode": "global_semantic_unification",
                "success": unification_result.success,
                "message": f"å…¨å±€è¯­ä¹‰ç»Ÿä¸€å®Œæˆ: å¤„ç†{unification_result.total_entities_processed}ä¸ªå®ä½“ï¼Œåˆå¹¶{unification_result.entities_merged}ä¸ªï¼Œåˆ é™¤{unification_result.entities_deleted}ä¸ªé‡å¤"
            }
        )
        
        # æ›´æ–°ä»»åŠ¡çŠ¶æ€ä¸ºå®Œæˆ
        await task_service.update_task_status(
            task_id=task_id,
            status=TaskStatus.COMPLETED
        )
        
        # æ¨é€æœ€ç»ˆçŠ¶æ€
        await push_task_update(task_id, task_service, task_detail_service)
        
        logger.info("Global semantic entity unification completed: %s", unification_result)
        
        return {
            "success": unification_result.success,
            "mode": "global_semantic_unification",
            "input_count": len(entities_data),
            "total_processed": unification_result.total_entities_processed,
            "entities_merged": unification_result.entities_merged,
            "entities_deleted": unification_result.entities_deleted,
            "relationships_updated": unification_result.relationships_updated,
            "processing_time": unification_result.processing_time,
            "type_statistics": unification_result.type_statistics,
            "errors": unification_result.errors,
            "summary": f"å…¨å±€è¯­ä¹‰ç»Ÿä¸€å®Œæˆ: å¤„ç†{unification_result.total_entities_processed}ä¸ªå®ä½“ï¼Œåˆå¹¶{unification_result.entities_merged}ä¸ªï¼Œåˆ é™¤{unification_result.entities_deleted}ä¸ªé‡å¤ï¼Œè€—æ—¶{unification_result.processing_time:.3f}ç§’"
        }
        
    except Exception as e:
        logger.error("Global semantic entity unification failed: %s", str(e))
        logger.error(f"å¼‚å¸¸è°ƒç”¨æ ˆ:\n{traceback.format_exc()}")
        
        # æ›´æ–°ä»»åŠ¡çŠ¶æ€ä¸ºå¤±è´¥
        await task_service.update_task_status(
            task_id=task_id,
            status=TaskStatus.FAILED,
            error_message=str(e)
        )
        
        # æ¨é€é”™è¯¯çŠ¶æ€
        await push_task_update(task_id, task_service, task_detail_service)
        raise
        
    finally:
        session.close()


async def _execute_incremental_unification(entities_data, task_id, task_detail_service):
    """æ‰§è¡Œå¢é‡ç»Ÿä¸€"""
    # åˆ›å»ºä»»åŠ¡è¯¦æƒ…è®°å½•
    detail = task_detail_service.create_task_detail(
        task_id=task_id,
        step_name="å¢é‡å®ä½“ç»Ÿä¸€",
        step_order=0
    )
    
    try:
        # ğŸ†• ä½¿ç”¨æ–°çš„ç±»å‹åˆ†ç»„å®ä½“ç»Ÿä¸€æœåŠ¡
        logger.info("æ‰§è¡Œå¢é‡å®ä½“ç»Ÿä¸€ï¼Œè¾“å…¥ %d ä¸ªå®ä½“æ•°æ®", len(entities_data))
        
        # æ›´æ–°ä»»åŠ¡è¯¦æƒ…ä¸ºè¿è¡Œä¸­
        task_detail_service.update_task_detail(
            task_detail_id=detail.id,
            status=TaskStatus.RUNNING,
            progress=10,
            details={"step": "åˆå§‹åŒ–å®ä½“ç»Ÿä¸€æœåŠ¡", "entity_count": len(entities_data)}
        )
        
        # å¯¼å…¥å®ä½“ç»Ÿä¸€æœåŠ¡
        from app.services.entity_unification_service import get_entity_unification_service
        from app.services.entity_extraction_service import EntityExtractionService
        
        # è·å–å®ä½“ç»Ÿä¸€æœåŠ¡å®ä¾‹
        unification_service = get_entity_unification_service()
        
        # è½¬æ¢å®ä½“æ•°æ®ä¸ºå®ä½“å¯¹è±¡
        from app.models.entity import Entity
        entities = []
        for data in entities_data:
            try:
                entity = Entity(
                    id=data.get('id'),
                    name=data.get('name'),
                    type=data.get('type', 'unknown'),
                    entity_type=data.get('entity_type', data.get('type', 'unknown')),
                    description=data.get('description', ''),
                    properties=data.get('properties', {}),
                    confidence=data.get('confidence', 0.8),
                    source_text=data.get('source_text', ''),
                    start_pos=data.get('start_pos', 0),
                    end_pos=data.get('end_pos', 0),
                    chunk_neo4j_id=data.get('chunk_neo4j_id'),
                    document_postgresql_id=data.get('document_postgresql_id'),
                    document_neo4j_id=data.get('document_neo4j_id'),
                    embedding=data.get('embedding'),
                    quality_score=data.get('quality_score', 0.8),
                    importance_score=data.get('importance_score', 0.5)
                )
                entities.append(entity)
            except Exception as e:
                logger.warning("è·³è¿‡æ— æ•ˆå®ä½“æ•°æ®: %s", str(e))
                continue
        
        logger.info("æˆåŠŸè½¬æ¢ %d ä¸ªå®ä½“å¯¹è±¡", len(entities))
        
        # æ›´æ–°ä»»åŠ¡è¯¦æƒ…
        task_detail_service.update_task_detail(
            task_detail_id=detail.id,
            status=TaskStatus.RUNNING,
            progress=30,
            details={"step": "å¼€å§‹å®ä½“ç»Ÿä¸€", "validated_entities": len(entities)}
        )
        
        # æ‰§è¡Œå®ä½“ç»Ÿä¸€
        unification_result = await unification_service.unify_entities(entities)
        
        # æ›´æ–°ä»»åŠ¡è¯¦æƒ…
        task_detail_service.update_task_detail(
            task_detail_id=detail.id,
            status=TaskStatus.RUNNING,
            progress=80,
            details={
                "step": "å®ä½“ç»Ÿä¸€å®Œæˆ",
                "input_count": unification_result.statistics['input_entity_count'],
                "output_count": unification_result.statistics['output_entity_count'],
                "merge_count": unification_result.statistics['merge_operation_count'],
                "reduction_rate": unification_result.statistics['reduction_rate'],
                "processing_time": unification_result.processing_time,
                "processing_strategy": unification_result.statistics.get('processing_strategy', 'unknown')
            }
        )
        
        # æœ€ç»ˆå®Œæˆ
        task_detail_service.update_task_detail(
            task_detail_id=detail.id,
            status=TaskStatus.COMPLETED,
            progress=100,
            details={
                "input_entities": len(entities_data),
                "output_entities": len(unification_result.unified_entities),
                "merge_operations": len(unification_result.merge_operations),
                "processing_time": unification_result.processing_time,
                "quality_metrics": unification_result.quality_metrics,
                "statistics": unification_result.statistics,
                "mode": "incremental_type_grouping",
                "message": "å¢é‡ç±»å‹åˆ†ç»„ç»Ÿä¸€å®Œæˆ: %d -> %d (å‡å°‘ %d ä¸ªé‡å¤)" % (
                    len(entities_data), 
                    len(unification_result.unified_entities), 
                    len(entities_data) - len(unification_result.unified_entities)
                )
            }
        )
        
        return {
            "success": True,
            "mode": "incremental_type_grouping",
            "input_count": len(entities_data),
            "output_count": len(unification_result.unified_entities),
            "merge_count": len(unification_result.merge_operations),
            "reduction_rate": unification_result.statistics['reduction_rate'],
            "processing_time": unification_result.processing_time,
            "quality_metrics": unification_result.quality_metrics,
            "processing_strategy": unification_result.statistics.get('processing_strategy'),
            "summary": "å¢é‡ç±»å‹åˆ†ç»„ç»Ÿä¸€å®Œæˆ: %d -> %d (å‡å°‘ %d ä¸ªé‡å¤), è€—æ—¶: %.3fç§’" % (
                len(entities_data), 
                len(unification_result.unified_entities), 
                len(entities_data) - len(unification_result.unified_entities),
                unification_result.processing_time
            )
        }
        
    except Exception as e:
        # æ›´æ–°ä»»åŠ¡è¯¦æƒ…ä¸ºå¤±è´¥
        task_detail_service.update_task_detail(
            task_detail_id=detail.id,
            status=TaskStatus.FAILED,
            error_message=str(e)
        )
        raise


async def _execute_sampling_unification(entities_data, task_id, task_detail_service):
    """æ‰§è¡ŒæŠ½æ ·ç»Ÿä¸€"""
    # åˆ›å»ºä»»åŠ¡è¯¦æƒ…è®°å½•
    detail = task_detail_service.create_task_detail(
        task_id=task_id,
        step_name="æŠ½æ ·å®ä½“ç»Ÿä¸€",
        step_order=0
    )
    
    try:
        # ğŸ†• ä½¿ç”¨æ–°çš„ç±»å‹åˆ†ç»„æŠ½æ ·å®ä½“ç»Ÿä¸€æœåŠ¡
        logger.info("æ‰§è¡ŒæŠ½æ ·å®ä½“ç»Ÿä¸€ï¼Œè¾“å…¥ %d ä¸ªå®ä½“æ•°æ®", len(entities_data))
        
        # æŒ‰å®ä½“ç±»å‹åˆ†ç»„
        entity_types = set(data.get('type', 'unknown') for data in entities_data)
        logger.info("å‘ç° %d ä¸ªå®ä½“ç±»å‹: %s", len(entity_types), list(entity_types))
        
        # æ›´æ–°ä»»åŠ¡è¯¦æƒ…ä¸ºè¿è¡Œä¸­
        task_detail_service.update_task_detail(
            task_detail_id=detail.id,
            status=TaskStatus.RUNNING,
            progress=10,
            details={
                "step": "åˆå§‹åŒ–æŠ½æ ·ç»Ÿä¸€æœåŠ¡", 
                "entity_count": len(entities_data),
                "entity_types": list(entity_types)
            }
        )
        
        # å¯¼å…¥å®ä½“ç»Ÿä¸€æœåŠ¡
        from app.services.entity_unification_service import get_entity_unification_service
        from app.services.entity_extraction_service import EntityExtractionService
        
        # è·å–å®ä½“ç»Ÿä¸€æœåŠ¡å®ä¾‹
        unification_service = get_entity_unification_service()
        
        # è½¬æ¢å®ä½“æ•°æ®ä¸ºå®ä½“å¯¹è±¡
        from app.models.entity import Entity
        entities = []
        for data in entities_data:
            try:
                entity = Entity(
                    id=data.get('id'),
                    name=data.get('name'),
                    type=data.get('type', 'unknown'),
                    entity_type=data.get('entity_type', data.get('type', 'unknown')),
                    description=data.get('description', ''),
                    properties=data.get('properties', {}),
                    confidence=data.get('confidence', 0.8),
                    source_text=data.get('source_text', ''),
                    start_pos=data.get('start_pos', 0),
                    end_pos=data.get('end_pos', 0),
                    chunk_neo4j_id=data.get('chunk_neo4j_id'),
                    document_postgresql_id=data.get('document_postgresql_id'),
                    document_neo4j_id=data.get('document_neo4j_id'),
                    embedding=data.get('embedding'),
                    quality_score=data.get('quality_score', 0.8),
                    importance_score=data.get('importance_score', 0.5)
                )
                entities.append(entity)
            except Exception as e:
                logger.warning("è·³è¿‡æ— æ•ˆå®ä½“æ•°æ®: %s", str(e))
                continue
        
        logger.info("æˆåŠŸè½¬æ¢ %d ä¸ªå®ä½“å¯¹è±¡", len(entities))
        
        # æ›´æ–°ä»»åŠ¡è¯¦æƒ…
        task_detail_service.update_task_detail(
            task_detail_id=detail.id,
            status=TaskStatus.RUNNING,
            progress=30,
            details={
                "step": "å¼€å§‹æŠ½æ ·ç»Ÿä¸€", 
                "validated_entities": len(entities),
                "entity_types": list(entity_types)
            }
        )
        
        # æ‰§è¡ŒæŠ½æ ·ç»Ÿä¸€ï¼ˆä½¿ç”¨ç±»å‹åˆ†ç»„ç­–ç•¥ï¼‰
        unification_result = await unification_service.unify_entities(entities)
        
        # æ›´æ–°ä»»åŠ¡è¯¦æƒ…
        task_detail_service.update_task_detail(
            task_detail_id=detail.id,
            status=TaskStatus.RUNNING,
            progress=80,
            details={
                "step": "æŠ½æ ·ç»Ÿä¸€å®Œæˆ",
                "input_count": unification_result.statistics['input_entity_count'],
                "output_count": unification_result.statistics['output_entity_count'],
                "merge_count": unification_result.statistics['merge_operation_count'],
                "reduction_rate": unification_result.statistics['reduction_rate'],
                "processing_time": unification_result.processing_time,
                "processing_strategy": unification_result.statistics.get('processing_strategy', 'unknown'),
                "entity_types_processed": list(entity_types)
            }
        )
        
        # æœ€ç»ˆå®Œæˆ
        task_detail_service.update_task_detail(
            task_detail_id=detail.id,
            status=TaskStatus.COMPLETED,
            progress=100,
            details={
                "input_entities": len(entities_data),
                "output_entities": len(unification_result.unified_entities),
                "merge_operations": len(unification_result.merge_operations),
                "processing_time": unification_result.processing_time,
                "quality_metrics": unification_result.quality_metrics,
                "statistics": unification_result.statistics,
                "entity_types_processed": list(entity_types),
                "mode": "sampling_type_grouping",
                "message": "æŠ½æ ·ç±»å‹åˆ†ç»„ç»Ÿä¸€å®Œæˆ: %d -> %d (å‡å°‘ %d ä¸ªé‡å¤), å¤„ç† %d ä¸ªç±»å‹" % (
                    len(entities_data), 
                    len(unification_result.unified_entities), 
                    len(entities_data) - len(unification_result.unified_entities),
                    len(entity_types)
                )
            }
        )
        
        return {
            "success": True,
            "mode": "sampling_type_grouping",
            "input_count": len(entities_data),
            "output_count": len(unification_result.unified_entities),
            "merge_count": len(unification_result.merge_operations),
            "reduction_rate": unification_result.statistics['reduction_rate'],
            "processing_time": unification_result.processing_time,
            "quality_metrics": unification_result.quality_metrics,
            "processing_strategy": unification_result.statistics.get('processing_strategy'),
            "entity_types": list(entity_types),
            "summary": "æŠ½æ ·ç±»å‹åˆ†ç»„ç»Ÿä¸€å®Œæˆ: %d -> %d (å‡å°‘ %d ä¸ªé‡å¤), å¤„ç† %d ä¸ªç±»å‹, è€—æ—¶: %.3fç§’" % (
                len(entities_data), 
                len(unification_result.unified_entities), 
                len(entities_data) - len(unification_result.unified_entities),
                len(entity_types),
                unification_result.processing_time
            )
        }
        
    except Exception as e:
        # æ›´æ–°ä»»åŠ¡è¯¦æƒ…ä¸ºå¤±è´¥
        task_detail_service.update_task_detail(
            task_detail_id=detail.id,
            status=TaskStatus.FAILED,
            error_message=str(e)
        )
        raise


@celery_app.task(name="trigger_document_entity_unification")
def trigger_document_entity_unification(document_id, extracted_entities, unification_mode="incremental"):
    """æ–‡æ¡£è§£æå®Œæˆåè§¦å‘å®ä½“ç»Ÿä¸€"""
    import uuid
    from datetime import datetime
    
    logger.info("Triggering entity unification for document %d with %d entities, mode: %s", 
                document_id, len(extracted_entities), unification_mode)
    
    # ä½¿ç”¨æ ‡å‡†UUIDç”Ÿæˆä»»åŠ¡ID
    task_id = str(uuid.uuid4())
    
    # åˆ›å»ºå‹å¥½çš„æ ‡è¯†ç¬¦ç”¨äºæ—¥å¿—å’Œmetadata
    friendly_id = "entity_unification_%d_%s" % (document_id, datetime.now().strftime('%Y%m%d_%H%M%S'))
    
    # åˆ›å»ºä»»åŠ¡è®°å½•
    try:
        session = SessionLocal()
        task_service = TaskService(session)
        
        # åˆ›å»ºä»»åŠ¡å¯¹è±¡
        from app.models.task import Task, TaskStatus
        task = Task(
            id=task_id,  # ä½¿ç”¨æ ‡å‡†UUID
            name=f"å®ä½“ç»Ÿä¸€: æ–‡æ¡£{document_id}",
            task_type="ENTITY_UNIFICATION",
            created_by=1,  # ç³»ç»Ÿç”¨æˆ·ID
            document_id=str(document_id),
            description=f"å¯¹æ–‡æ¡£{document_id}çš„{len(extracted_entities)}ä¸ªå®ä½“è¿›è¡Œ{unification_mode}ç»Ÿä¸€",
            task_metadata={
                "entity_count": len(extracted_entities),
                "unification_mode": unification_mode,
                "document_id": document_id,
                "friendly_id": friendly_id  # ä¿å­˜å‹å¥½æ ‡è¯†ç¬¦
            },
            status=TaskStatus.PENDING,
            progress=0.0,
            created_at=datetime.now(timezone.utc)
        )
        
        # ä¿å­˜åˆ°æ•°æ®åº“
        session.add(task)
        session.commit()
        session.refresh(task)
        
        logger.info("Entity unification task created successfully: %s (friendly_id: %s)", task_id, friendly_id)
        
    except Exception as e:
        logger.error("Failed to create entity unification task: %s", str(e))
        session.rollback()
        raise
    finally:
        session.close()
    
    # å¯åŠ¨å¼‚æ­¥ç»Ÿä¸€ä»»åŠ¡
    if unification_mode == "global_semantic":
        # ä½¿ç”¨æ–°çš„å…¨å±€è¯­ä¹‰ç»Ÿä¸€ä»»åŠ¡
        global_semantic_entity_unification_task.delay(
            document_id=document_id,
            task_id=task_id,  # ä¼ é€’æ ‡å‡†UUID
            entities_data=extracted_entities
        )
    else:
        # ä½¿ç”¨åŸæœ‰çš„å¢é‡ç»Ÿä¸€ä»»åŠ¡
        incremental_entity_unification_task.delay(
            document_id=document_id,
            task_id=task_id,  # ä¼ é€’æ ‡å‡†UUID
            entities_data=extracted_entities,
            mode=unification_mode
        )
    
    return {
        "status": "triggered",
        "document_id": document_id,
        "task_id": task_id,  # è¿”å›æ ‡å‡†UUID
        "friendly_id": friendly_id,  # è¿”å›å‹å¥½æ ‡è¯†ç¬¦
        "entity_count": len(extracted_entities),
        "mode": unification_mode
    } 