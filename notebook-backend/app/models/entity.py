import logging
from typing import List, Dict, Any, Optional
from dataclasses import dataclass
from datetime import datetime
from enum import Enum

logger = logging.getLogger(__name__)

class EntityLifecycleState(Enum):
    """å®ä½“ç”Ÿå‘½å‘¨æœŸçŠ¶æ€æšä¸¾"""
    NEW = "new"           # æ–°åˆ›å»ºçš„å®ä½“
    STABLE = "stable"     # ç¨³å®šçš„å®ä½“
    SUSPICIOUS = "suspicious"  # å¯ç–‘çš„å®ä½“ï¼ˆå¯èƒ½éœ€è¦ç»Ÿä¸€ï¼‰
    DEPRECATED = "deprecated"  # åºŸå¼ƒçš„å®ä½“

@dataclass
class Entity:
    """å®ä½“æ•°æ®ç±» - ç»Ÿä¸€ç‰ˆæœ¬æ”¯æŒæ™ºèƒ½å®ä½“ç»Ÿä¸€
    
    è¿™æ˜¯ç³»ç»Ÿä¸­å”¯ä¸€çš„Entityå®šä¹‰ï¼ŒåŒ…å«æ‰€æœ‰å¿…è¦çš„å­—æ®µå’ŒéªŒè¯é€»è¾‘
    """
    id: str
    name: str
    type: str
    description: str
    properties: Dict[str, Any]
    confidence: float
    source_text: str
    start_pos: int
    end_pos: int
    
    # æ‰©å±•å­—æ®µï¼ˆç”¨äºå›¾è°±å­˜å‚¨ï¼‰
    chunk_neo4j_id: Optional[str] = None
    document_postgresql_id: Optional[int] = None
    document_neo4j_id: Optional[str] = None
    chunk_index: int = 0
    entity_index: int = 0
    
    # ğŸ†• å®ä½“ç»Ÿä¸€å¢å¼ºå­—æ®µ
    aliases: List[str] = None  # åˆ«ååˆ—è¡¨
    embedding: Optional[List[float]] = None  # å‘é‡è¡¨ç¤º
    quality_score: float = 1.0  # è´¨é‡åˆ†æ•°
    
    # ğŸ†• åˆå¹¶è¿½è¸ªå­—æ®µï¼ˆç”¨äºæ™ºèƒ½ç»Ÿä¸€ï¼‰
    merged_from: Optional[List[str]] = None  # åˆå¹¶æºå®ä½“IDåˆ—è¡¨
    merge_timestamp: Optional[str] = None  # åˆå¹¶æ—¶é—´æˆ³
    
    # ğŸ†• å¢é‡ç»Ÿä¸€ä¸“ç”¨å­—æ®µ
    entity_type: Optional[str] = None  # å…·ä½“ç±»å‹ï¼šå…¬å¸ã€äººç‰©ã€äº§å“ç­‰
    lifecycle_state: EntityLifecycleState = EntityLifecycleState.NEW  # ç”Ÿå‘½å‘¨æœŸçŠ¶æ€
    importance_score: float = 0.0  # é‡è¦æ€§åˆ†æ•°
    last_unified_at: Optional[datetime] = None  # æœ€åç»Ÿä¸€æ—¶é—´
    fingerprint: Optional[str] = None  # å®ä½“æŒ‡çº¹
    created_at: Optional[datetime] = None  # åˆ›å»ºæ—¶é—´
    updated_at: Optional[datetime] = None  # æ›´æ–°æ—¶é—´
    last_referenced_at: Optional[datetime] = None  # æœ€åå¼•ç”¨æ—¶é—´
    reference_count: int = 0  # å¼•ç”¨è®¡æ•°
    relationship_count: int = 0  # å…³ç³»è®¡æ•°
    
    def __post_init__(self):
        """åˆå§‹åŒ–åå¤„ç†ï¼Œç¡®ä¿å‘åå…¼å®¹æ€§å’Œæ•°æ®éªŒè¯"""
        if self.aliases is None:
            self.aliases = []
        
        if self.merged_from is None:
            self.merged_from = []
        
        # éªŒè¯å’Œæ¸…ç†aliasesåˆ—è¡¨
        self.aliases = self._validate_and_clean_aliases(self.aliases)
        
        # ç¡®ä¿è´¨é‡åˆ†æ•°åœ¨åˆç†èŒƒå›´å†…
        if self.quality_score < 0.0 or self.quality_score > 1.0:
            self.quality_score = min(1.0, max(0.0, self.quality_score))
        
        # ç¡®ä¿é‡è¦æ€§åˆ†æ•°åœ¨åˆç†èŒƒå›´å†…
        if self.importance_score < 0.0 or self.importance_score > 1.0:
            self.importance_score = min(1.0, max(0.0, self.importance_score))
        
        # éªŒè¯embeddingå‘é‡
        if self.embedding is not None:
            self.embedding = self._validate_embedding(self.embedding)
        
        # è®¾ç½®é»˜è®¤æ—¶é—´æˆ³
        current_time = datetime.now()
        if self.created_at is None:
            self.created_at = current_time
        if self.updated_at is None:
            self.updated_at = current_time
        if self.last_referenced_at is None:
            self.last_referenced_at = current_time
        
        # å¦‚æœæ²¡æœ‰æŒ‡å®šentity_typeï¼Œä½¿ç”¨typeå­—æ®µ
        if self.entity_type is None:
            self.entity_type = self.type
        
        # ç”ŸæˆæŒ‡çº¹
        if self.fingerprint is None:
            self.fingerprint = self._generate_fingerprint()
    
    def _validate_and_clean_aliases(self, aliases: List[str]) -> List[str]:
        """éªŒè¯å’Œæ¸…ç†åˆ«ååˆ—è¡¨"""
        if not aliases:
            return []
        
        cleaned_aliases = []
        for alias in aliases:
            if isinstance(alias, str) and alias.strip():
                # æ ‡å‡†åŒ–åˆ«å
                cleaned_alias = alias.strip()
                # é¿å…è‡ªå·±æˆä¸ºè‡ªå·±çš„åˆ«å
                if cleaned_alias != self.name and cleaned_alias not in cleaned_aliases:
                    cleaned_aliases.append(cleaned_alias)
        
        return cleaned_aliases
    
    def _validate_embedding(self, embedding: List[float]) -> Optional[List[float]]:
        """éªŒè¯embeddingå‘é‡"""
        if not embedding:
            return None
        
        try:
            # ç¡®ä¿æ‰€æœ‰å…ƒç´ éƒ½æ˜¯æ•°å­—
            validated_embedding = [float(x) for x in embedding]
            
            # æ£€æŸ¥å‘é‡ç»´åº¦ï¼ˆé¢„æœŸç»´åº¦å¯ä»¥ä»é…ç½®ä¸­è·å–ï¼‰
            from app.core.config import settings
            expected_dim = getattr(settings, 'VECTOR_SIZE', 1536)  # é»˜è®¤1536ç»´
            
            if len(validated_embedding) != expected_dim:
                logger.warning(f"Embeddingç»´åº¦ä¸åŒ¹é…: æœŸæœ›{expected_dim}, å®é™…{len(validated_embedding)}")
                # å¦‚æœç»´åº¦ä¸åŒ¹é…ï¼Œè¿”å›Noneè€Œä¸æ˜¯æŠ›å‡ºå¼‚å¸¸
                return None
            
            return validated_embedding
            
        except (ValueError, TypeError) as e:
            logger.warning(f"EmbeddingéªŒè¯å¤±è´¥: {str(e)}")
            return None
    
    def add_alias(self, alias: str) -> bool:
        """æ·»åŠ åˆ«å"""
        if alias and alias.strip() and alias != self.name:
            clean_alias = alias.strip()
            if clean_alias not in self.aliases:
                self.aliases.append(clean_alias)
                return True
        return False
    
    def get_all_names(self) -> List[str]:
        """è·å–æ‰€æœ‰åç§°ï¼ˆåŒ…æ‹¬ä¸»åç§°å’Œåˆ«åï¼‰"""
        return [self.name] + self.aliases
    
    def is_merged_entity(self) -> bool:
        """åˆ¤æ–­æ˜¯å¦ä¸ºåˆå¹¶åçš„å®ä½“"""
        return bool(self.merged_from and len(self.merged_from) > 0)
    
    def _generate_fingerprint(self) -> str:
        """ç”Ÿæˆå®ä½“æŒ‡çº¹ï¼Œç”¨äºå¿«é€Ÿå˜æ›´æ£€æµ‹"""
        import hashlib
        
        # ä½¿ç”¨å…³é”®å­—æ®µç”ŸæˆæŒ‡çº¹
        fingerprint_data = f"{self.name}|{self.type}|{self.description}|{self.quality_score}|{len(self.aliases)}"
        return hashlib.md5(fingerprint_data.encode('utf-8')).hexdigest()
    
    def update_fingerprint(self) -> str:
        """æ›´æ–°å®ä½“æŒ‡çº¹"""
        self.fingerprint = self._generate_fingerprint()
        self.updated_at = datetime.now()
        return self.fingerprint
    
    def has_changed(self, other_fingerprint: str) -> bool:
        """æ£€æŸ¥å®ä½“æ˜¯å¦å‘ç”Ÿå˜æ›´"""
        return self.fingerprint != other_fingerprint
    
    def calculate_completeness(self) -> float:
        """è®¡ç®—ä¿¡æ¯å®Œæ•´åº¦"""
        total_fields = 5  # name, type, description, properties, aliases
        filled_fields = 0
        
        if self.name and self.name.strip():
            filled_fields += 1
        if self.type and self.type.strip():
            filled_fields += 1
        if self.description and self.description.strip():
            filled_fields += 1
        if self.properties and len(self.properties) > 0:
            filled_fields += 1
        if self.aliases and len(self.aliases) > 0:
            filled_fields += 1
        
        return filled_fields / total_fields
    
    def calculate_recency(self) -> float:
        """è®¡ç®—æ—¶æ•ˆæ€§åˆ†æ•°"""
        from datetime import timedelta
        
        if self.last_referenced_at is None:
            return 0.0
        
        now = datetime.now()
        time_diff = now - self.last_referenced_at
        
        # 30å¤©å†…çš„å®ä½“å¾—åˆ†è¾ƒé«˜
        if time_diff <= timedelta(days=30):
            return 1.0 - (time_diff.days / 30.0)
        else:
            return 0.0
    
    def update_importance_score(self) -> float:
        """æ›´æ–°é‡è¦æ€§åˆ†æ•°"""
        score = 0.0
        
        # å¼•ç”¨é¢‘ç‡æƒé‡ (40%)
        score += min(self.reference_count * 0.1, 0.4)
        
        # å…³ç³»ä¸°å¯Œåº¦æƒé‡ (30%)
        score += min(self.relationship_count * 0.05, 0.3)
        
        # ä¿¡æ¯å®Œæ•´åº¦æƒé‡ (20%)
        score += self.calculate_completeness() * 0.2
        
        # æ—¶æ•ˆæ€§æƒé‡ (10%)
        score += self.calculate_recency() * 0.1
        
        self.importance_score = min(score, 1.0)
        return self.importance_score
    
    def update_lifecycle_state(self) -> EntityLifecycleState:
        """æ›´æ–°ç”Ÿå‘½å‘¨æœŸçŠ¶æ€"""
        from datetime import timedelta
        
        now = datetime.now()
        
        # æ–°å®ä½“ï¼šåˆ›å»ºæ—¶é—´<24h
        if self.created_at and now - self.created_at < timedelta(hours=24):
            self.lifecycle_state = EntityLifecycleState.NEW
        # åºŸå¼ƒå®ä½“ï¼š90å¤©æœªè¢«å¼•ç”¨
        elif self.last_referenced_at and now - self.last_referenced_at > timedelta(days=90):
            self.lifecycle_state = EntityLifecycleState.DEPRECATED
        # å¯ç–‘å®ä½“ï¼šè´¨é‡åˆ†æ•°ä½æˆ–æœ€è¿‘è¢«ä¿®æ”¹
        elif self.quality_score < 0.6 or (self.updated_at and now - self.updated_at < timedelta(hours=1)):
            self.lifecycle_state = EntityLifecycleState.SUSPICIOUS
        else:
            self.lifecycle_state = EntityLifecycleState.STABLE
        
        return self.lifecycle_state
    
    def mark_referenced(self):
        """æ ‡è®°å®ä½“è¢«å¼•ç”¨"""
        self.reference_count += 1
        self.last_referenced_at = datetime.now()
        self.update_lifecycle_state()
    
    def to_dict(self) -> Dict[str, Any]:
        """è½¬æ¢ä¸ºå­—å…¸æ ¼å¼"""
        return {
            'id': self.id,
            'name': self.name,
            'type': self.type,
            'entity_type': self.entity_type,
            'description': self.description,
            'properties': self.properties,
            'confidence': self.confidence,
            'quality_score': self.quality_score,
            'importance_score': self.importance_score,
            'aliases': self.aliases,
            'merged_from': self.merged_from,
            'merge_timestamp': self.merge_timestamp,
            'lifecycle_state': self.lifecycle_state.value,
            'fingerprint': self.fingerprint,
            'created_at': self.created_at.isoformat() if self.created_at else None,
            'updated_at': self.updated_at.isoformat() if self.updated_at else None,
            'last_referenced_at': self.last_referenced_at.isoformat() if self.last_referenced_at else None,
            'last_unified_at': self.last_unified_at.isoformat() if self.last_unified_at else None,
            'reference_count': self.reference_count,
            'relationship_count': self.relationship_count
        }


@dataclass  
class Relationship:
    """å…³ç³»æ•°æ®ç±» - ç»Ÿä¸€ç‰ˆæœ¬"""
    id: str
    source_entity_id: str
    target_entity_id: str
    source_entity_name: str
    target_entity_name: str
    relationship_type: str
    description: str
    properties: Dict[str, Any]
    confidence: float
    source_text: str
    context: str
    
    # æ‰©å±•å­—æ®µï¼ˆç”¨äºå›¾è°±å­˜å‚¨ï¼‰
    chunk_neo4j_id: Optional[str] = None
    document_postgresql_id: Optional[int] = None
    document_neo4j_id: Optional[str] = None


@dataclass
class KnowledgeExtractionResult:
    """çŸ¥è¯†æŠ½å–ç»“æœ"""
    entities: List[Entity]
    relationships: List[Relationship]
    chunk_id: str
    chunk_index: int
    success: bool
    error_message: Optional[str] = None 